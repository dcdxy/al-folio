---
---

@string{aps = {American Physical Society,}}

@article{Denisko2018,
  abbr = {{PNAS}},
  abstract = {Suppose you are a physician with a patient whose complaint could arise from multiple diseases. To attain a specific diagnosis, you might ask yourself a series of yes/no questions depending on observed features describing the patient, such as clinical test results and reported symptoms. As some questions rule out certain diagnoses early on, each answer determines which question you ask next. With about a dozen features and extensive medical knowledge, you could create a simple flow chart to connect and order these questions. If you had observations of thousands of features instead, you would probably want to automate. Machine learning methods can learn which questions to ask about these features to classify the entity they describe. Even when we lack prior knowledge, a classifier can tell us which features are most important and how they relate to, or interact with, each other. Identifying interactions with large numbers of features poses a special challenge. In PNAS, Basu et al. (1) address this problem with a new classifier based on the widely used random forest technique. The new method, an iterative random forest algorithm (iRF), increases the robustness of random forest classifiers and provides a valuable new way to identify important feature interactions.Random forests came into the spotlight in 2001 after their description by Breiman (2). He was largely influenced by previous work, especially the similar “randomized trees” method of Amit and Geman (3), as well as Ho's “random decision forests” (4). Random forests have since proven useful in many fields due to their high predictive accuracy (5, 6). In biology and medicine, random forests have successfully tackled a range of problems, including predicting drug response in cancer cell lines (7), identifying DNA-binding proteins (8), and localizing cancer to particular tissues from a liquid biopsy (9). Random forests have also {\ldots} ↵1To whom correspondence should be addressed. Email: michael.hoffman{\{}at{\}}utoronto.ca.},
  author = {Denisko, Danielle and Hoffman, Michael M},
  doi = {10.1073/pnas.1800256115},
  issn = {0027-8424},
  journal = {Proceedings of the National Academy of Sciences},
  mendeley-groups = {Commentary},
  month = {feb},
  number = {8},
  pages = {1690--1692},
  pmid = {29440440},
  title = {{Classification and interaction in random forests}},
  url = {http://www.pnas.org/content/115/8/1690.abstract},
  volume = {115},
  year = {2018}
}

@article {Denisko721720,
  abbr = {bioRxiv},
	author = {Denisko, Danielle and Viner, Coby and Hoffman, Michael M.},
	title = {Motif elucidation in ChIP-seq datasets with a knockout control},
	elocation-id = {721720},
	year = {2019},
	doi = {10.1101/721720},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Chromatin immunoprecipitation-sequencing (ChIP-seq) is widely used to find transcription factor binding sites, but suffers from various sources of noise. Knocking out the target factor mitigates noise by acting as a negative control. Paired wild-type and knockout experiments can generate improved motifs but require optimal differential analysis. We introduce peaKO{\textemdash}a method to automatically optimize motif analyses with knockout controls, which we compare to two other methods. PeaKO often improves elucidation of the target factor and highlights the benefits of knockout controls, which far outperform input controls. It is freely available at https://peako.hoffmanlab.org.},
	URL = {https://www.biorxiv.org/content/early/2019/10/22/721720},
	eprint = {https://www.biorxiv.org/content/early/2019/10/22/721720.full.pdf},
	journal = {bioRxiv}
}
